{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fb8fdc7-05ff-47f3-8d43-37d2e6792006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels after cleanup: ['negative' 'neutral' 'positive']\n",
      "Warning: Unable to read text file C:/Users/cpj/Desktop/ECNU/大三第一学期/当代人工智能/实验5/data\\5084.txt due to error: 'gbk' codec can't decode byte 0xac in position 75: illegal multibyte sequence\n",
      "Classes found by LabelEncoder: ['negative' 'neutral' 'positive']\n",
      "Encoded labels range: 0 to 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cpj\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\cpj\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [07:32<00:00,  4.52s/it]\n",
      "Evaluating: 100%|██████████| 25/25 [00:39<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.8999, Val Loss = 0.8422, Val Accuracy = 0.6025\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [07:23<00:00,  4.43s/it]\n",
      "Evaluating: 100%|██████████| 25/25 [00:37<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss = 0.7844, Val Loss = 0.8087, Val Accuracy = 0.6325\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [07:27<00:00,  4.48s/it]\n",
      "Evaluating: 100%|██████████| 25/25 [00:35<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss = 0.7183, Val Loss = 0.7914, Val Accuracy = 0.6312\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [07:31<00:00,  4.51s/it]\n",
      "Evaluating: 100%|██████████| 25/25 [00:38<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss = 0.6605, Val Loss = 0.7858, Val Accuracy = 0.6338\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [07:24<00:00,  4.44s/it]\n",
      "Evaluating: 100%|██████████| 25/25 [00:35<00:00,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss = 0.5868, Val Loss = 0.7892, Val Accuracy = 0.6388\n",
      "Total Training Time: 2425.80 seconds\n",
      "Model saved at C:/Users/cpj/Desktop/ECNU/大三第一学期/当代人工智能/实验5/output\\emotion_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm  # 用于可视化进度条\n",
    "\n",
    "# 设置路径\n",
    "data_dir = \"C:/Users/cpj/Desktop/ECNU/大三第一学期/当代人工智能/实验5/data\"\n",
    "train_file = \"C:/Users/cpj/Desktop/ECNU/大三第一学期/当代人工智能/实验5/train.txt\"\n",
    "test_file = \"C:/Users/cpj/Desktop/ECNU/大三第一学期/当代人工智能/实验5/test_without_label.txt\"\n",
    "output_dir = \"C:/Users/cpj/Desktop/ECNU/大三第一学期/当代人工智能/实验5/output\"\n",
    "\n",
    "# 创建输出目录（如果不存在）\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 加载训练集标签\n",
    "train_df = pd.read_csv(train_file, header=None, names=[\"guid\", \"label\"])\n",
    "\n",
    "# 清理数据确保标签合法\n",
    "valid_labels = [\"positive\", \"neutral\", \"negative\"]  # 只允许这三种标签\n",
    "train_df = train_df[train_df[\"label\"].isin(valid_labels)]  # 过滤出合法数据\n",
    "\n",
    "# 验证清理后的标签\n",
    "print(f\"Training labels after cleanup: {train_df['label'].unique()}\")\n",
    "\n",
    "# 文本预处理（使用 TF-IDF）\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # 限制最大特征数量\n",
    "train_texts = []\n",
    "\n",
    "# 读取文本内容\n",
    "for guid in train_df[\"guid\"]:\n",
    "    text_path = os.path.join(data_dir, f\"{guid}.txt\")\n",
    "    try:\n",
    "        with open(text_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            train_texts.append(file.read())\n",
    "    except UnicodeDecodeError:\n",
    "        try:\n",
    "            with open(text_path, \"r\", encoding=\"gbk\") as file:\n",
    "                train_texts.append(file.read())\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Unable to read text file {text_path} due to error: {e}\")\n",
    "            train_texts.append(\"[TEXT_ERROR]\")  # 占位符\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: File not found - {text_path}\")\n",
    "        train_texts.append(\"[TEXT_MISSING]\")  # 占位符\n",
    "\n",
    "# 对文本进行 TF-IDF 转换\n",
    "X_text = tfidf_vectorizer.fit_transform(train_texts).toarray()\n",
    "\n",
    "# 图像预处理\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# 标签编码\n",
    "label_encoder = LabelEncoder()\n",
    "y_labels = label_encoder.fit_transform(train_df[\"label\"])\n",
    "\n",
    "# 打印编码后的标签及其范围\n",
    "print(f\"Classes found by LabelEncoder: {label_encoder.classes_}\")\n",
    "print(f\"Encoded labels range: {y_labels.min()} to {y_labels.max()}\")\n",
    "\n",
    "# 加载图像\n",
    "image_tensors = []\n",
    "for guid in train_df[\"guid\"]:\n",
    "    image_path = os.path.join(data_dir, f\"{guid}.jpg\")\n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: Image file not found - {image_path}\")\n",
    "        image = Image.new(\"RGB\", (224, 224))  # 如果图片不存在，生成空白图片\n",
    "    image_tensor = image_transform(image)\n",
    "    image_tensors.append(image_tensor)\n",
    "\n",
    "# 切分数据集\n",
    "X_train_text, X_val_text, X_train_images, X_val_images, y_train, y_val = train_test_split(\n",
    "    X_text, image_tensors, y_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 创建数据集类\n",
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, text_features, image_tensors, labels):\n",
    "        self.text_features = text_features\n",
    "        self.image_tensors = image_tensors\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.text_features[idx], dtype=torch.float32), self.image_tensors[idx], torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "# 创建数据集和DataLoader\n",
    "train_dataset = MultimodalDataset(X_train_text, X_train_images, y_train)\n",
    "val_dataset = MultimodalDataset(X_val_text, X_val_images, y_val)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 模型设计\n",
    "class MultimodalEmotionModel(nn.Module):\n",
    "    def __init__(self, text_input_dim, num_classes):\n",
    "        super(MultimodalEmotionModel, self).__init__()\n",
    "\n",
    "        # 文本特征提取\n",
    "        self.text_fc = nn.Linear(text_input_dim, 256)\n",
    "\n",
    "        # 图像特征提取\n",
    "        self.resnet = models.resnet18(pretrained=True)\n",
    "        self.resnet.fc = nn.Identity()  # 去掉ResNet的最后一层全连接层\n",
    "        self.image_fc = nn.Linear(512, 256)  # ResNet18输出维度为512\n",
    "\n",
    "        # 融合层\n",
    "        self.fusion_fc = nn.Linear(512, num_classes)  # 动态设置输出类别数\n",
    "\n",
    "    def forward(self, text_features, image_tensor):\n",
    "        # 文本特征\n",
    "        text_output = self.text_fc(text_features)\n",
    "\n",
    "        # 图像特征\n",
    "        image_features = self.resnet(image_tensor)\n",
    "        image_features = self.image_fc(image_features)\n",
    "\n",
    "        # 融合特征\n",
    "        combined_features = torch.cat((text_output, image_features), dim=1)\n",
    "        output = self.fusion_fc(combined_features)\n",
    "        return output\n",
    "\n",
    "# 确定输出类别数\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# 实例化模型\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MultimodalEmotionModel(text_input_dim=X_text.shape[1], num_classes=num_classes).to(device)\n",
    "\n",
    "# 损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# 训练过程\n",
    "def train(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for text_features, image_tensor, labels in tqdm(dataloader, desc=\"Training\"):\n",
    "        text_features = text_features.to(device)\n",
    "        image_tensor = image_tensor.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(text_features, image_tensor)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    return avg_loss\n",
    "\n",
    "# 评估过程\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for text_features, image_tensor, labels in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            text_features = text_features.to(device)\n",
    "            image_tensor = image_tensor.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            output = model(text_features, image_tensor)\n",
    "            loss = criterion(output, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# 训练和评估\n",
    "start_time = time.time()\n",
    "for epoch in range(5):\n",
    "    print(f\"Epoch {epoch+1}/{5}\")\n",
    "\n",
    "    train_loss = train(model, train_dataloader, optimizer, criterion, device)\n",
    "    val_loss, val_accuracy = evaluate(model, val_dataloader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}, Val Accuracy = {val_accuracy:.4f}\")\n",
    "\n",
    "# 总时间\n",
    "end_time = time.time()\n",
    "print(f\"Total Training Time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# 保存模型\n",
    "model_save_path = os.path.join(output_dir, \"emotion_model.pth\")\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model saved at {model_save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
